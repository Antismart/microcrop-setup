# Data Processor Analysis - Do We Still Need It?

## ğŸ” Executive Summary

**Short Answer:** âš ï¸ **PARTIALLY DEPRECATED** - The data-processor has significant overlap with your new CRE workflow, but some components are still valuable.

**Recommendation:** Keep the backend API parts, deprecate the duplicate oracle/blockchain submission logic.

---

## ğŸ“¦ What the Data Processor Does

The `data-processor` is a **Python-based data pipeline** that was designed to:

### Core Functions:
1. âœ… **Weather Data Processing** - Real-time WeatherXM data ingestion and analysis
2. âš ï¸ **Satellite Imagery Processing** - NDVI calculation from raw satellite images (DEPRECATED by Planet Biomass)
3. âš ï¸ **Damage Calculation** - 60% weather + 40% satellite formula (NOW IN CRE WORKFLOW)
4. âš ï¸ **Blockchain Oracle Submissions** - Submit data on-chain (REPLACED BY CRE)
5. âœ… **Time-Series Storage** - TimescaleDB for historical weather data
6. âœ… **API Endpoints** - FastAPI REST API for data queries
7. âœ… **WebSocket Streaming** - Real-time updates to frontend dashboard
8. âœ… **Celery Workers** - Distributed async task processing

### Technology Stack:
```
Python 3.10+ with:
- FastAPI (REST API)
- Celery (async workers)
- Rasterio/GDAL (satellite image processing)
- NumPy/Pandas (data analysis)
- TimescaleDB (time-series storage)
- Kafka (event streaming)
- MinIO (object storage)
- Redis (caching)
```

---

## ğŸ”„ Overlap with CRE Workflow

### âŒ **DEPRECATED Components** (Now handled by CRE):

#### 1. **Manual NDVI Calculation**
**Data Processor Code:**
```python
# src/processors/satellite_processor.py
class SatelliteProcessor:
    async def process_satellite_capture(self, image_data: bytes):
        # Opens raw satellite images with rasterio
        # Calculates NDVI manually from Red/NIR bands
        # Returns vegetation indices
```

**Why Deprecated:**
- âŒ Your CRE workflow now uses Planet Labs **Crop Biomass Proxy** instead
- âŒ Manual NDVI calculation is less accurate than Planet's industry-standard metric
- âŒ Complex raster processing no longer needed

#### 2. **Damage Calculation Logic**
**Data Processor Code:**
```python
# src/processors/damage_calculator.py
class DamageCalculator:
    async def calculate_damage(self, weather_indices, satellite_images):
        # 60% weather + 40% satellite formula
        # Growth stage multipliers
        # Payout trigger evaluation
```

**Why Deprecated:**
- âŒ Same logic now lives in **CRE workflow** (`main.ts`)
- âŒ Duplication of business logic
- âŒ CRE provides decentralized consensus, Python doesn't

#### 3. **Blockchain Oracle Submissions**
**Data Processor Code:**
```python
# src/workers/blockchain_tasks.py
@celery_app.task
def submit_weather_to_blockchain(weather_data):
    # Submits weather data to WeatherOracle contract
    
@celery_app.task
def submit_satellite_to_blockchain(satellite_data):
    # Submits satellite data to SatelliteOracle contract
```

**Why Deprecated:**
- âŒ Oracle contracts are deprecated (you moved to CRE)
- âŒ CRE workflow handles on-chain submissions via PayoutReceiver
- âŒ Direct blockchain writes from Python are less reliable than CRE

---

## âœ… **KEEP These Components** (Still Useful):

### 1. **Weather Data Collection & Storage**
**Purpose:** Collect and store historical weather data for CRE workflow to query

**Why Keep:**
- âœ… CRE workflow needs to fetch weather data via API
- âœ… TimescaleDB provides efficient time-series storage
- âœ… Caching layer speeds up repeated queries
- âœ… Historical baseline calculations

**Usage in CRE:**
```typescript
// cre-workflow/src/main.ts
function fetchWeatherData(nodeRuntime: NodeRuntime<Config>, policy: Policy): WeatherData {
  // Calls backend API which queries TimescaleDB
  const response = httpClient.sendRequest(nodeRuntime, {
    url: `${config.backendApiUrl}/api/weather/${stationId}?days=30`,
  }).result()
}
```

### 2. **FastAPI Backend Endpoints**
**Purpose:** Provide REST API for CRE workflow and dashboard

**Why Keep:**
- âœ… CRE workflow calls backend for weather data
- âœ… CRE workflow calls backend for Planet Biomass data
- âœ… Dashboard queries backend for analytics
- âœ… GPS coordinate lookups via plotId (privacy-preserving)

**Key Endpoints Needed:**
```python
# Keep these endpoints:
GET /api/weather/{station_id}  # Weather data for damage assessment
GET /api/planet/biomass/{plot_id}  # Planet subscription data (NEW)
GET /api/policy/{policy_id}  # Policy details
GET /api/damage-history/{plot_id}  # Historical assessments
```

### 3. **Planet Subscription Management** (NEW - TO BUILD)
**Purpose:** Manage Planet Labs subscriptions for each policy

**Why Keep:**
- âœ… Required for Planet Biomass integration
- âœ… Creates subscriptions when policies activate
- âœ… Fetches latest biomass data from Planet API
- âœ… Handles subscription lifecycle (create/cancel)

**Implementation Needed:**
```python
# NEW FILE: src/integrations/planet_client.py
class PlanetClient:
    async def create_biomass_subscription(self, policy_id, field_geometry, dates):
        # POST to Planet Subscriptions API
        # Returns subscription_id
        
    async def get_biomass_timeseries(self, subscription_id):
        # Fetches latest CSV from Planet
        # Returns biomass values
        
    async def cancel_subscription(self, subscription_id):
        # Cancels when policy expires
```

### 4. **Dashboard WebSocket Streaming**
**Purpose:** Real-time updates to frontend dashboard

**Why Keep:**
- âœ… Dashboard needs live weather updates
- âœ… Push notifications for damage assessments
- âœ… Real-time policy status changes

**Usage:**
```python
# src/api/websocket.py
async def broadcast_damage_assessment(plot_id: str, damage_data: dict):
    # Pushes to connected dashboard clients
```

### 5. **Historical Data Analytics**
**Purpose:** Query historical patterns for baselines and reporting

**Why Keep:**
- âœ… Calculate weather baselines (e.g., "normal" rainfall for region)
- âœ… Generate reports for farmers and insurers
- âœ… Audit trail for claims

---

## ğŸ—ï¸ Recommended Architecture

### **Keep This Flow:**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Data Processor (Python)                  â”‚
â”‚                                                              â”‚
â”‚  1. WeatherXM Webhook â†’ Store in TimescaleDB                â”‚
â”‚  2. Planet Subscription Manager â†’ Fetch biomass data        â”‚
â”‚  3. FastAPI Endpoints:                                      â”‚
â”‚     - GET /api/weather/{station}                            â”‚
â”‚     - GET /api/planet/biomass/{plot_id}                     â”‚
â”‚     - GET /api/policy/{policy_id}                           â”‚
â”‚  4. WebSocket â†’ Push updates to dashboard                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    (HTTP API calls)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              Chainlink CRE Workflow (TypeScript)             â”‚
â”‚                                                              â”‚
â”‚  1. Fetch active policies from PolicyManager                â”‚
â”‚  2. Fetch weather data from backend API                     â”‚
â”‚  3. Fetch biomass data from backend API                     â”‚
â”‚  4. Calculate damage (60% weather + 40% biomass)            â”‚
â”‚  5. Submit payout to PayoutReceiver contract                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                            â†“
                    (Smart contract call)
                            â†“
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                 Smart Contracts (Solidity)                   â”‚
â”‚                                                              â”‚
â”‚  PayoutReceiver â†’ Treasury â†’ Transfer USDC to farmer        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ—‘ï¸ Files to Deprecate in Data Processor

### Deprecated Files (Safe to Remove or Archive):

```bash
# Satellite processing (replaced by Planet Biomass API)
data-processor/src/processors/satellite_processor.py
data-processor/src/analyzers/ndvi_analyzer.py
data-processor/src/integrations/spexi_client.py  # Old satellite provider

# Damage calculation (moved to CRE)
data-processor/src/processors/damage_calculator.py
data-processor/src/models/damage.py

# Blockchain oracle (replaced by CRE)
data-processor/src/workers/blockchain_tasks.py
data-processor/src/integrations/blockchain_client.py
data-processor/src/processors/oracle_processor.py
```

### Files to Keep and Update:

```bash
# Weather data collection (still needed)
data-processor/src/processors/weather_processor.py
data-processor/src/integrations/weatherxm_client.py
data-processor/src/models/weather_models.py

# Storage and caching (still needed)
data-processor/src/storage/timescale_client.py
data-processor/src/storage/redis_cache.py

# API endpoints (still needed - update to remove satellite/damage endpoints)
data-processor/src/api/app.py
data-processor/src/api/routes.py
data-processor/src/api/websocket.py

# Workers (keep for weather processing)
data-processor/src/workers/celery_app.py
data-processor/src/workers/weather_tasks.py

# NEW: Add Planet integration
data-processor/src/integrations/planet_client.py  # TO CREATE
```

---

## ğŸ“ Action Items

### Phase 1: Clean Up Data Processor (Week 1)

1. **Archive Deprecated Files:**
   ```bash
   cd /Users/onchainchef/Desktop/microcrop-setup/data-processor
   mkdir deprecated
   mv src/processors/satellite_processor.py deprecated/
   mv src/processors/damage_calculator.py deprecated/
   mv src/workers/blockchain_tasks.py deprecated/
   mv src/integrations/spexi_client.py deprecated/
   ```

2. **Create DEPRECATED_DATA_PROCESSOR.md:**
   - Document what was removed and why
   - List components still in use
   - Migration path for any old integrations

### Phase 2: Add Planet Integration (Week 2)

3. **Create Planet Client:**
   ```bash
   touch data-processor/src/integrations/planet_client.py
   ```
   
4. **Implement Planet Endpoints:**
   - `POST /api/planet/subscription` - Create new subscription when policy activates
   - `GET /api/planet/biomass/{plot_id}` - Fetch biomass data for CRE workflow
   - `DELETE /api/planet/subscription/{subscription_id}` - Cancel when policy expires

5. **Add to Backend API:**
   ```python
   # data-processor/src/api/routes.py
   @router.get("/api/planet/biomass/{plot_id}")
   async def get_biomass_data(plot_id: int):
       # Fetch from Planet subscription
       # Return biomass timeseries
   ```

### Phase 3: Update Documentation (Week 2)

6. **Update README.md:**
   - Remove references to satellite image processing
   - Remove references to damage calculation
   - Remove references to blockchain oracle
   - Add Planet Labs integration section
   - Update architecture diagram

7. **Create NEW_ARCHITECTURE.md:**
   - Document CRE + Backend API flow
   - Show separation of concerns
   - API contract between CRE and backend

---

## ğŸ’° Cost Impact

### Before (Full Data Processor):
```
Infrastructure:
- PostgreSQL/TimescaleDB: $50/month
- Redis: $20/month
- Kafka: $100/month (likely overkill now)
- MinIO: $30/month
- Compute (Python workers): $200/month
TOTAL: $400/month
```

### After (Simplified Backend):
```
Infrastructure:
- PostgreSQL/TimescaleDB: $50/month (keep for weather data)
- Redis: $20/month (keep for caching)
- Kafka: $0 (remove - not needed for CRE integration)
- MinIO: $0 (remove - no longer storing satellite images)
- Compute (reduced workers): $100/month
TOTAL: $170/month

SAVINGS: $230/month (58% reduction)
```

---

## âœ… Final Recommendations

### **KEEP:**
1. âœ… Weather data collection and storage (WeatherXM integration)
2. âœ… FastAPI backend for CRE workflow to query
3. âœ… TimescaleDB for time-series weather data
4. âœ… Redis caching layer
5. âœ… WebSocket streaming to dashboard
6. âœ… Historical analytics endpoints

### **DEPRECATE:**
1. âŒ Manual satellite image processing (use Planet Biomass API)
2. âŒ NDVI calculation logic (Planet handles this)
3. âŒ Damage calculation in Python (moved to CRE workflow)
4. âŒ Blockchain oracle submission tasks (CRE handles this)
5. âŒ Kafka streaming (overkill for current scale)
6. âŒ MinIO storage (no longer storing raw imagery)

### **ADD:**
1. ğŸ†• Planet Labs subscription management
2. ğŸ†• `/api/planet/biomass/{plot_id}` endpoint
3. ğŸ†• GPS coordinate â†’ plotId mapping (privacy)

---

## ğŸ¯ Summary

**The data-processor is still valuable as a backend API service**, but needs significant cleanup:

- **Remove:** 60% of code (satellite processing, damage calculation, blockchain submissions)
- **Keep:** 30% of code (weather data, API endpoints, storage)
- **Add:** 10% new code (Planet integration, biomass endpoints)

**Think of it as:** Your backend API server that the CRE workflow calls for data, not as a competing damage assessment system.

**Benefits of keeping simplified backend:**
- âœ… Centralized weather data storage
- âœ… Planet subscription management
- âœ… GPS privacy (coordinates stay off-chain)
- âœ… Dashboard analytics and reporting
- âœ… Historical baseline calculations
- âœ… Audit trail for compliance

**Next step:** Review and clean up as outlined in Action Items above.
